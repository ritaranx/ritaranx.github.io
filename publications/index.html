<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Ran Xu


  | Publications

</title>
<meta name="description" content="">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Nunito:300,400,500,700|Nunito+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://combinatronics.io/jwarby/pygments-css/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üêæ</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/publications/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-XXXXXXXXX"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-XXXXXXXXX');
</script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

  <!-- Nav Bar -->
  <nav id="navbar"
    class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://ritaranx.github.io/">
        Ran Xu
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav"
        aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              About
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
            <a class="nav-link" href="/assets/pdf/cv.pdf">
              CV
              
            </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
            <a class="nav-link" href="/services/">
              Misc
              
            </a>
          </li>
          
          
          
          
          
          <li class="nav-item active">
            <a class="nav-link" href="/publications/">
              Publications
              
              <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          
          
          
          
          
          <div class="toggle-container">
            <a id="light-toggle">
              <i class="fas fa-moon"></i>
              <i class="fas fa-sun"></i>
            </a>
          </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>

    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">Publications</h1>
    <p class="post-description">Publications by categories in reversed chronological order. Full list is available on my <a href="https://scholar.google.com/citations?hl=en&user=mcC5NzwAAAAJ"><b>Google Scholar</b></a>.</p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2024</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>

  <div id="xu2024simrag" class="col-sm-10">
    
    <div class="title"><b>SimRAG: Self-Improving Retrieval-Augmented Generation for Adapting Large Language Models to Specialized Domains</b>
    </div>
    <div class="author">
      
      
      
      
      
      

      
      
      
      <em>Ran Xu</em>,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Hui Liu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Sreyashi Nag,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Zhenwei Dai,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yaochen Xie,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Xianfeng Tang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Chen Luo,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yang Li,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Joyce C Ho,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Carl Yang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Qi He
      
      
      
      
      
    </div>

    <div class="periodical">
      
      <em>arXiv preprint arXiv:2410.17952</em>,
      <!-- (preprint) -->
      
      
      2024.  
      
      
      
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      
      <a href="http://arxiv.org/abs/2410.17952" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
      
      
      
      
      
      
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>

  <div id="shen2024boosting" class="col-sm-10">
    
    <div class="title"><b>Boosting reward model with preference-conditional multi-aspect synthetic data generation</b>
    </div>
    <div class="author">
      
      
      
      
      
      

      
      
      
      
      Jiaming Shen,
      
      
      
      
      
      
      
      
      
      

      
      
      
      <em>Ran Xu</em>,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yennie Jun,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Zhen Qin,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Tianqi Liu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Carl Yang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yi Liang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Simon Baumgartner,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Michael Bendersky
      
      
      
      
      
    </div>

    <div class="periodical">
      
      <em>arXiv preprint arXiv:2407.16008</em>,
      <!-- (preprint) -->
      
      
      2024.  
      
      
      
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      
      <a href="http://arxiv.org/abs/2407.16008" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
      
      
      
      
      
      
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>

  <div id="xu-etal-2024-bmretriever" class="col-sm-10">
    
    <div class="title"><b>BMRetriever: Tuning Large Language Models as Better Biomedical Text Retrievers</b>
    </div>
    <div class="author">
      
      
      
      
      
      

      
      
      
      <em>Ran Xu*</em>,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Wenqi Shi*,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yue Yu*,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yuchen Zhuang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yanqiao Zhu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      May Dongmei Wang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Joyce C. Ho,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Chao Zhang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Carl Yang
      
      
      
      
      
    </div>

    <div class="periodical">
      
      Proceedings of <em>EMNLP</em>, 
      <!-- /*(EMNLP)*/ -->
      <!-- Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing -->
      
      
      2024.  
      
      
      
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      <a href="http://arxiv.org/abs/2404.18443" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
      
      
      
      
      
      
      
      <a href="https://github.com/ritaranx/BMRetriever" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Developing effective biomedical retrieval models is important for excelling at knowledge-intensive biomedical tasks but still challenging due to the lack of sufficient publicly annotated biomedical data and computational resources. We present BMRetriever, a series of dense retrievers for enhancing biomedical retrieval via unsupervised pre-training on large biomedical corpora, followed by instruction fine-tuning on a combination of labeled datasets and synthetic pairs. Experiments on 5 biomedical tasks across 11 datasets verify BMRetriever‚Äôs efficacy on various biomedical applications. BMRetriever also exhibits strong parameter efficiency, with the 410M variant outperforming baselines up to 11.7 times larger, and the 2B variant matching the performance of models with over 5B parameters. The training data and model checkpoints are released at https://huggingface.co/BMRetriever to ensure transparency, reproducibility, and application to new domains.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>

  <div id="shi-etal-2024-medadapter" class="col-sm-10">
    
    <div class="title"><b>MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning</b>
    </div>
    <div class="author">
      
      
      
      
      
      

      
      
      
      
      Wenqi Shi*,
      
      
      
      
      
      
      
      
      
      

      
      
      
      <em>Ran Xu*</em>,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yuchen Zhuang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yue Yu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Haotian Sun,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Hang Wu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Carl Yang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      and May Dongmei Wang
      
      
      
      
      
    </div>

    <div class="periodical">
      
      Proceedings of <em>EMNLP</em>, 
      <!-- /*(EMNLP)*/ -->
      <!-- Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing -->
      
      
      2024.  
      
      
      
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      <a href="http://arxiv.org/abs/2405.03000" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
      
      
      
      
      
      
      
      <a href="https://github.com/wshi83/MedAdapter" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Despite their improved capabilities in generation and reasoning, adapting large language models (LLMs) to the biomedical domain remains challenging due to their immense size and privacy concerns. In this study, we propose MedAdapter, a unified post-hoc adapter for test-time adaptation of LLMs towards biomedical applications. Instead of fine-tuning the entire LLM, MedAdapter effectively adapts the original model by fine-tuning only a small BERT-sized adapter to rank candidate solutions generated by LLMs. Experiments on four biomedical tasks across eight datasets demonstrate that MedAdapter effectively adapts both white-box and black-box LLMs in biomedical reasoning, achieving average performance improvements of 18.24% and 10.96%, respectively, without requiring extensive computational resources or sharing data with third parties. MedAdapter also yields enhanced performance when combined with train-time adaptation, highlighting a flexible and complementary solution to existing adaptation methods. Faced with the challenges of balancing model performance, computational resources, and data privacy, MedAdapter provides an efficient, privacy-preserving, cost-effective, and transparent solution for adapting LLMs to the biomedical domain.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>

  <div id="shi-etal-2024-ehragent" class="col-sm-10">
    
    <div class="title"><b>EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records</b>
    </div>
    <div class="author">
      
      
      
      
      
      

      
      
      
      
      Wenqi Shi*,
      
      
      
      
      
      
      
      
      
      

      
      
      
      <em>Ran Xu*</em>,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yuchen Zhuang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yue Yu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Jieyu Zhang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Hang Wu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yuanda Zhu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Joyce C. Ho,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Carl Yang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      and May Dongmei Wang
      
      
      
      
      
    </div>

    <div class="periodical">
      
      Proceedings of <em>EMNLP</em>, 
      <!-- /*(EMNLP)*/ -->
      <!-- Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing -->
      
      
      2024.  
      
      
      
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      <a href="http://arxiv.org/abs/2401.07128" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
      
      
      
      
      
      
      
      <a href="https://github.com/wshi83/EHRAgent" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Clinicians often rely on data engineers to retrieve complex patient information from electronic health record (EHR) systems, a process that is both inefficient and time-consuming. We propose EHRAgent, a large language model (LLM) agent empowered with accumulative domain knowledge and robust coding capability. EHRAgent enables autonomous code generation and execution to facilitate clinicians in directly interacting with EHRs using natural language. Specifically, we formulate a multi-tabular reasoning task based on EHRs as a tool-use planning process, efficiently decomposing a complex task into a sequence of manageable actions with external toolsets. We first inject relevant medical information to enable EHRAgent to effectively reason about the given query, identifying and extracting the required records from the appropriate tables. By integrating interactive coding and execution feedback, EHRAgent then effectively learns from error messages and iteratively improves its originally generated code. Experiments on three real-world EHR datasets show that EHRAgent outperforms the strongest baseline by up to 29.6% in success rate, verifying its strong capacity to tackle complex clinical tasks with minimal demonstrations.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>

  <div id="xu-etal-2024-knowledge" class="col-sm-10">
    
    <div class="title"><b>Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models</b>
    </div>
    <div class="author">
      
      
      
      
      
      

      
      
      
      <em>Ran Xu</em>,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Hejie Cui,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yue Yu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Xuan Kan,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Wenqi Shi,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yuchen Zhuang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      May Dongmei Wang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Wei Jin,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Joyce Ho,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Carl Yang
      
      
      
      
      
    </div>

    <div class="periodical">
      
      Proceedings of <em>ACL (Findings)</em>, 
      <!-- /*(ACL (Findings))*/ -->
      <!-- Findings of the Association for Computational Linguistics: ACL 2024 -->
      
      
      2024.  
      
      
      
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      <a href="http://arxiv.org/abs/2311.00287" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
      
      
      
      
      
      
      
      <a href="https://github.com/ritaranx/ClinGen" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Clinical natural language processing faces challenges like complex medical terminology and clinical contexts. Recently, large language models (LLMs) have shown promise in this domain. Yet, their direct deployment can lead to privacy issues and are constrained by resources. To address this challenge, we delve into synthetic clinical text generation with LLMs for clinical NLP tasks. We propose an innovative, resource-efficient approach, ClinGen, which infuses knowledge into the process. Our model involves clinical knowledge extraction and context-informed LLM prompting. Both clinical topics and writing styles are drawn from external domain-specific knowledge graphs and LLMs to guide data generation. Our extensive empirical study across 8 clinical NLP tasks and 18 datasets reveals that ClinGen consistently enhances performance across various tasks by 7.7%-8.7% on average, effectively aligning the distribution of real datasets and enriching the diversity of generated training instances.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>

  <div id="xu-etal-2024-ram" class="col-sm-10">
    
    <div class="title"><b>RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic Health Records</b>
    </div>
    <div class="author">
      
      
      
      
      
      

      
      
      
      <em>Ran Xu</em>,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Wenqi Shi,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yue Yu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yuchen Zhuang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Bowen Jin,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      May Dongmei Wang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Joyce Ho,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Carl Yang
      
      
      
      
      
    </div>

    <div class="periodical">
      
      Proceedings of <em>ACL</em>, 
      <!-- /*(ACL)*/ -->
      <!-- Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) -->
      
      
      2024.  
      
      
      (<font color="red">Oral</font>)
      
      
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
      
      
      <a href="https://github.com/ritaranx/RAM-EHR" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We present RAM-EHR, a Retrieval AugMentation pipeline to improve clinical predictions on Electronic Health Records (EHRs). RAM-EHR first collects multiple knowledge sources, converts them into text format, and uses dense retrieval to obtain information related to medical concepts. This strategy addresses the difficulties associated with complex names for the concepts. RAM-EHR then augments the local EHR predictive model co-trained with consistency regularization to capture complementary information from patient visits and summarized knowledge. Experiments on two EHR datasets show the efficacy of RAM-EHR over previous knowledge-enhanced baselines (3.4% gain in AUROC and 7.2% gain in AUPR), emphasizing the effectiveness of the summarized knowledge from RAM-EHR for clinical prediction tasks.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>

  <div id="pmlr-v248-xu24a" class="col-sm-10">
    
    <div class="title"><b>From Basic to Extra Features: Hypergraph Transformer Pretrain-then-Finetuning for Balanced Clinical Predictions on EHR</b>
    </div>
    <div class="author">
      
    </div>

    <div class="periodical">
      
      Proceedings of <em>CHIL</em>, 
      <!-- /*(CHIL)*/ -->
      <!-- Proceedings of the fifth Conference on Health, Inference, and Learning -->
      
      
      2024.  
      
      
      
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
      <a href="https://raw.githubusercontent.com/mlresearch/v248/main/assets/xu24a/xu24a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
      
      
      
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Electronic Health Records (EHRs) contain rich patient information and are crucial for clinical research and practice.  In recent years, deep learning models have been applied to EHRs, but they often rely on massive features, which may not be readily available for all patients. We propose \ours\footnoteShort for \textbfHypergraph \textbfTransformer \textbfPretrain-then-Finetuning with \textbfSmoo\textbfthness-induced regularization \textbfand \textbfReweighting., which leverages hypergraph structures with a pretrain-then-finetune framework for modeling EHR data, enabling seamless integration of additional features.  Additionally, we design two techniques, namely (1) \emphSmoothness-inducing Regularization and (2) \emphGroup-balanced Reweighting, to enhance the model‚Äôs robustness during finetuning. Through experiments conducted on two real EHR datasets, we demonstrate that \ours consistently outperforms various baselines while striking a balance between patients with basic and extra features.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>

  <div id="zhang2024tacco" class="col-sm-10">
    
    <div class="title"><b>TACCO: Task-guided Co-clustering of Clinical Concepts and Patient Visits for Disease Subtyping based on EHR Data</b>
    </div>
    <div class="author">
      
      
      
      
      
      

      
      
      
      
      Ziyang Zhang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Hejie Cui,
      
      
      
      
      
      
      
      
      
      

      
      
      
      <em>Ran Xu</em>,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yuzhang Xie,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Joyce C Ho,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Carl Yang
      
      
      
      
      
    </div>

    <div class="periodical">
      
      Proceedings of <em>KDD</em>, 
      <!-- /*(KDD)*/ -->
      <!-- Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining -->
      
      
      2024.  
      
      
      
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      
      <a href="http://arxiv.org/abs/2406.10061" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
      
      
      
      
      
      <a href="https://dl.acm.org/doi/10.1145/3637528.3671594" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
      
      
      
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li></ol>

  <h2 class="year">2023</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>

  <div id="xu2023weakly" class="col-sm-10">
    
    <div class="title"><b>Weakly-supervised Scientific Document Classification via Retrieval-Augmented Multi-stage Training</b>
    </div>
    <div class="author">
      
      
      
      
      
      

      
      
      
      <em>Ran Xu*</em>,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yue Yu*,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Joyce C Ho,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Carl Yang
      
      
      
      
      
    </div>

    <div class="periodical">
      
      Proceedings of <em>SIGIR</em>, 
      <!-- /*(SIGIR)*/ -->
      <!-- Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval -->
      
      
      2023.  
      
      
      
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      
      <a href="http://arxiv.org/abs/2306.07193" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
      
      
      
      
      
      
      
      <a href="https://github.com/ritaranx/WANDER" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>

  <div id="xu2023nest" class="col-sm-10">
    
    <div class="title"><b>Neighborhood-regularized Self-Training for Learning with Few Labels</b>
    </div>
    <div class="author">
      
      
      
      
      
      

      
      
      
      <em>Ran Xu</em>,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yue Yu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Hejie Cui,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Xuan Kan,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yanqiao Zhu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Joyce Ho,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Chao Zhang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Carl Yang
      
      
      
      
      
    </div>

    <div class="periodical">
      
      Proceedings of <em>AAAI</em>, 
      <!-- /*(AAAI)*/ -->
      <!-- Proceedings of the 37th AAAI Conference on Artificial Intelligence -->
      
      
      2023.  
      
      
      (<font color="red">Oral</font>)
      
      
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      
      <a href="http://arxiv.org/abs/2301.03726" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
      
      
      
      
      
      <a href="https://ojs.aaai.org/index.php/AAAI/article/view/26260/26032" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
      
      
      
      
      <a href="https://github.com/ritaranx/NeST" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>

  <div id="xu2023hypergraph" class="col-sm-10">
    
    <div class="title"><b>Hypergraph Transformers for EHR-based Clinical Predictions</b>
    </div>
    <div class="author">
      
      
      
      
      
      

      
      
      
      <em>Ran Xu</em>,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Mohammed K Ali,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Joyce C Ho,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Carl Yang
      
      
      
      
      
    </div>

    <div class="periodical">
      
      <em>AMIA Summits on Translational Science Proceedings</em>,
      <!-- (AMIA) -->
      
      
      2023.  
      
      
      (<font color="red">Oral</font>)
      
      
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      
      
      
      
      
      <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10283128/" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
      
      
      
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>

  <div id="cui2023open" class="col-sm-10">
    
    <div class="title"><b>Open Visual Knowledge Extraction via Relation-Oriented Multimodality Model Prompting</b>
    </div>
    <div class="author">
      
      
      
      
      
      

      
      
      
      
      Hejie Cui,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Xinyu Fang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Zihan Zhang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      <em>Ran Xu</em>,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Xuan Kan,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Xin Liu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yue Yu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Manling Li,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yangqiu Song,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Carl Yang
      
      
      
      
      
    </div>

    <div class="periodical">
      
      Proceedings of <em>NeurIPS</em>, 
      <!-- /*(NeurIPS)*/ -->
      <!-- Thirty-seventh Conference on Neural Information Processing Systems -->
      
      
      2023.  
      
      
      
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      
      <a href="http://arxiv.org/abs/2311.00287" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
      
      
      
      
      
      <a href="https://openreview.net/forum?id=ixVAXsdtJO" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
      
      
      
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>

  <div id="yu-etal-2023-cold" class="col-sm-10">
    
    <div class="title"><b>Cold-Start Data Selection for Better Few-shot Language Model Fine-tuning: A Prompt-based Uncertainty Propagation Approach</b>
    </div>
    <div class="author">
      
      
      
      
      
      

      
      
      
      
      Yue Yu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Rongzhi Zhang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      <em>Ran Xu</em>,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Jieyu Zhang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Jiaming Shen,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Chao Zhang
      
      
      
      
      
    </div>

    <div class="periodical">
      
      Proceedings of <em>ACL</em>, 
      <!-- /*(ACL)*/ -->
      <!-- Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) -->
      
      
      2023.  
      
      
      
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
      <a href="https://aclanthology.org/2023.acl-long.141.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
      
      
      
      
      <a href="https://github.com/yueyu1030/Patron" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We present PATRON, a prompt-based data selection method for pre-trained language model fine-tuning under cold-start scenarios, i.e., no initial labeled data are available. In PATRON, we design (1) a prompt-based uncertainty propagation approach to estimate the importance of data points and (2) a partition-then-rewrite (PTR) strategy to promote sample diversity when querying for annotations. Experiments on six text classification datasets show that PATRON outperforms the strongest cold-start data selection baselines by up to 6.9%. Besides, with 128 labels only, PATRON achieves 91.0% and 92.1% of the fully supervised performance based on vanilla fine-tuning and prompt-based learning respectively. Our implementation of PATRON will be published upon acceptance.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>

  <div id="kan2023rmixup" class="col-sm-10">
    
    <div class="title"><b>R-Mixup: Riemannian Mixup for Biological Networks</b>
    </div>
    <div class="author">
      
      
      
      
      
      

      
      
      
      
      Xuan Kan,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Zimu Li,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Hejie Cui,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yue Yu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      <em>Ran Xu</em>,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Shaojun Yu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Zilong Zhang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Ying Guo,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Carl Yang
      
      
      
      
      
    </div>

    <div class="periodical">
      
      Proceedings of <em>KDD</em>, 
      <!-- /*(KDD)*/ -->
      <!-- Proceedings of the 29th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining -->
      
      
      2023.  
      
      
      
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      
      <a href="http://arxiv.org/abs/2306.02532" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
      
      
      
      
      
      <a href="https://dl.acm.org/doi/pdf/10.1145/3580305.3599483" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
      
      
      
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>

  <div id="yu2022causal" class="col-sm-10">
    
    <div class="title"><b>Deep DAG Learning on Brain Networks for fMRI Analysis</b>
    </div>
    <div class="author">
      
      
      
      
      
      

      
      
      
      
      Yue Yu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Xuan Kan,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Hejie Cui,
      
      
      
      
      
      
      
      
      
      

      
      
      
      <em>Ran Xu</em>,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yujia Zheng,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Xiangchen Song,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yanqiao Zhu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Kun Zhang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Razieh Nabi,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Ying Guo,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Chao Zhang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Carl Yang
      
      
      
      
      
    </div>

    <div class="periodical">
      
      Proceedings of <em>ISBI</em>, 
      <!-- /*(ISBI)*/ -->
      <!-- Proceedings of the 20th IEEE International Symposium on Biomedical Imaging -->
      
      
      2023.  
      
      
      
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      
      <a href="http://arxiv.org/abs/2211.00261" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
      
      
      
      
      
      <a href="https://ieeexplore.ieee.org/abstract/document/10230429" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
      
      
      
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>

  <div id="cui2023a" class="col-sm-10">
    
    <div class="title"><b>A Survey on Knowledge Graphs for Healthcare: Resources, Application Progress, and Promise</b>
    </div>
    <div class="author">
      
      
      
      
      
      

      
      
      
      
      Hejie Cui,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Jiaying Lu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Shiyu Wang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      <em>Ran Xu</em>,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Wenjing Ma,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Shaojun Yu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yue Yu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Xuan Kan,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Tianfan Fu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Chen Ling,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Joyce Ho,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Fei Wang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Carl Yang
      
      
      
      
      
    </div>

    <div class="periodical">
      
      Proceedings of <em>ICML (IMLH Workshop)</em>, 
      <!-- /*(ICML (IMLH Workshop))*/ -->
      <!-- ICML 3rd Workshop on Interpretable Machine Learning in Healthcare (IMLH) -->
      
      
      2023.  
      
      
      
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      
      <a href="http://arxiv.org/abs/2306.04802" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
      
      
      
      
      
      <a href="https://openreview.net/forum?id=CZCktJoBRh" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
      
      
      
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li></ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>

  <div id="pmlr-v193-xu22a" class="col-sm-10">
    
    <div class="title"><b>Counterfactual and Factual Reasoning over Hypergraphs for Interpretable Clinical Predictions on EHR</b>
    </div>
    <div class="author">
      
      
      
      
      
      

      
      
      
      <em>Ran Xu</em>,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yue Yu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Chao Zhang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Mohammed K Ali,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Joyce C Ho,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Carl Yang
      
      
      
      
      
    </div>

    <div class="periodical">
      
      Proceedings of <em>ML4H</em>, 
      <!-- /*(ML4H)*/ -->
      <!-- Proceedings of the 2nd Machine Learning for Health symposium -->
      
      
      2022.  
      
      
      
      
      (<font color="red">Best Paper Award</font>)
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
      <a href="https://proceedings.mlr.press/v193/xu22a/xu22a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
      
      
      
      
      <a href="https://github.com/ritaranx/CACHE" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Electronic Health Record modeling is crucial for digital medicine. However, existing models ignore higher-order interactions among medical codes and their causal relations towards downstream clinical predictions. To address such limitations, we propose a novel framework CACHE, to provide <em>effective</em> and <em>insightful</em> clinical predictions based on hypergraph representation learning and counterfactual and factual reasoning techniques. Experiments on two real EHR datasets show the superior performance of CACHE. Case studies with a domain expert illustrate a preferred capability of CACHE in generating clinically meaningful interpretations towards the correct predictions.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li></ol>


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2024 Ran  Xu.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    
    Last updated: November 11, 2024.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
